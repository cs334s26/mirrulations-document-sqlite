{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Docket Ingestion to PostgreSQL + `cfrPart` Handling\n",
        "\n",
        "This notebook provides practical examples and repeatable process steps for:\n",
        "\n",
        "1. Ingesting one or more dockets into PostgreSQL using `ingest_dockets_postgres.py`\n",
        "2. Normalizing inconsistent `cfrPart` values via `cfr_part_normalization.py`\n",
        "3. Performing post-ingestion quality checks and triage\n",
        "\n",
        "> Commands are shown in a safe way first. Run the commented lines only when you are ready."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Process Overview\n",
        "\n",
        "**End-to-end flow**\n",
        "\n",
        "1. Configure environment (`DATABASE_URL`, `API_KEY`)\n",
        "2. Optionally initialize Postgres schema (`documents_schema_postgres.sql`)\n",
        "3. Ingest one or more docket IDs (`ingest_dockets_postgres.py`)\n",
        "4. Review `cfr_part_parse_status` distribution\n",
        "5. Inspect `unparsed` / `missing_title` examples\n",
        "6. Iterate parser rules and re-run targeted ingestion"
      ],
      "id": "ec904a76"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import shlex\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "ROOT = Path.cwd()\n",
        "INGEST_SCRIPT = ROOT / \"ingest_dockets_postgres.py\"\n",
        "SCHEMA_SQL = ROOT / \"documents_schema_postgres.sql\"\n",
        "\n",
        "DATABASE_URL = os.getenv(\"DATABASE_URL\", \"postgresql://user:password@host:5432/dbname\")\n",
        "API_KEY = os.getenv(\"API_KEY\", \"DEMO_KEY\")\n",
        "\n",
        "print(f\"Repo root: {ROOT}\")\n",
        "print(f\"Ingest script exists: {INGEST_SCRIPT.exists()}\")\n",
        "print(f\"Schema file exists: {SCHEMA_SQL.exists()}\")\n",
        "print(f\"DATABASE_URL set: {'DATABASE_URL' in os.environ}\")\n",
        "print(f\"API_KEY set: {'API_KEY' in os.environ}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "7122fb6d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def show_command(cmd: list[str]) -> None:\n",
        "    print(\" \".join(shlex.quote(part) for part in cmd))\n",
        "\n",
        "\n",
        "def run_command(cmd: list[str], execute: bool = False) -> subprocess.CompletedProcess | None:\n",
        "    \"\"\"Print command. Execute only when execute=True.\"\"\"\n",
        "    show_command(cmd)\n",
        "    if not execute:\n",
        "        print(\"(Not executed; set execute=True to run)\")\n",
        "        return None\n",
        "    return subprocess.run(cmd, check=False, text=True)\n",
        ""
      ],
      "execution_count": null,
      "outputs": [],
      "id": "0b55a481"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 1: Dry-run one docket (no database writes)\n",
        "\n",
        "Use this to validate API access and inspect parser status output before writing rows."
      ],
      "id": "5fa0f445"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "example_docket = \"CMS-2025-0304\"\n",
        "cmd = [\n",
        "    \"python3\",\n",
        "    str(INGEST_SCRIPT),\n",
        "    \"--dry-run\",\n",
        "    \"--api-key\",\n",
        "    API_KEY,\n",
        "    example_docket,\n",
        "]\n",
        "\n",
        "run_command(cmd, execute=False)\n",
        "# To run for real (still dry-run):\n",
        "# run_command(cmd, execute=True)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "bae8b394"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 2: Ingest multiple dockets into PostgreSQL\n",
        "\n",
        "This example writes docket IDs to a file and builds an ingestion command with schema initialization."
      ],
      "id": "8d056593"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "docket_ids = [\n",
        "    \"CMS-2025-0304\",\n",
        "    \"FDA-2024-N-1234\",\n",
        "]\n",
        "\n",
        "example_file = ROOT / \"example_docket_ids.txt\"\n",
        "example_file.write_text(\"\\n\".join(docket_ids) + \"\\n\", encoding=\"utf-8\")\n",
        "print(f\"Wrote {example_file} with {len(docket_ids)} IDs\")\n",
        "\n",
        "cmd = [\n",
        "    \"python3\",\n",
        "    str(INGEST_SCRIPT),\n",
        "    \"--init-schema\",\n",
        "    \"--schema\",\n",
        "    str(SCHEMA_SQL),\n",
        "    \"--database-url\",\n",
        "    DATABASE_URL,\n",
        "    \"--api-key\",\n",
        "    API_KEY,\n",
        "    \"--docket-file\",\n",
        "    str(example_file),\n",
        "]\n",
        "\n",
        "run_command(cmd, execute=False)\n",
        "# To run for real (writes to Postgres):\n",
        "# run_command(cmd, execute=True)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "5604b95b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 3: Normalize inconsistent `cfrPart` values\n",
        "\n",
        "The ingestion script stores both raw `cfr_part` and normalized JSON in `cfr_part_normalized` with status in `cfr_part_parse_status`.\n",
        "\n",
        "Common statuses:\n",
        "\n",
        "- `parsed`: title/part references extracted\n",
        "- `missing_title`: part numbers found but no explicit title (e.g., `Part 412`)\n",
        "- `unparsed`: explicit `CFR` text was present but parser could not extract parts\n",
        "- `no_cfr`: text did not look like CFR citations\n",
        "- `empty`: null/blank input"
      ],
      "id": "79a13121"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import json\n",
        "from cfr_part_normalization import normalize_cfr_part\n",
        "\n",
        "samples = [\n",
        "    \"42 CFR Part 412\",\n",
        "    \"42 CFR 412\",\n",
        "    \"42 CFR Parts 405, 417, 422, and 460\",\n",
        "    \"42 CFR Parts 410-412\",\n",
        "    \"42 CFR Part 412; 45 CFR Part 155\",\n",
        "    \"Part 412\",\n",
        "    \"RIN 0938-AV01\",\n",
        "]\n",
        "\n",
        "for value in samples:\n",
        "    normalized = normalize_cfr_part(value)\n",
        "    print(f\"INPUT: {value}\")\n",
        "    print(json.dumps(normalized, indent=2))\n",
        "    print(\"-\" * 72)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "16610c25"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 4: Post-ingestion quality checks in PostgreSQL\n",
        "\n",
        "Use these queries after ingesting dockets:\n",
        "\n",
        "1. Parse status distribution\n",
        "2. Sample problematic `cfr_part` rows (`unparsed`, `missing_title`)\n",
        "3. Confirm references for a target pair (for example, 42 CFR part 412)"
      ],
      "id": "34fed3b1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "status_query = \"\"\"\n",
        "SELECT cfr_part_parse_status, COUNT(*) AS n\n",
        "FROM documents\n",
        "GROUP BY cfr_part_parse_status\n",
        "ORDER BY n DESC;\n",
        "\"\"\"\n",
        "\n",
        "triage_query = \"\"\"\n",
        "SELECT document_id, docket_id, cfr_part_parse_status, cfr_part\n",
        "FROM documents\n",
        "WHERE cfr_part_parse_status IN ('unparsed', 'missing_title')\n",
        "ORDER BY posted_date DESC NULLS LAST\n",
        "LIMIT 50;\n",
        "\"\"\"\n",
        "\n",
        "part_412_query = \"\"\"\n",
        "SELECT document_id, docket_id, cfr_part\n",
        "FROM documents\n",
        "WHERE cfr_part_normalized @> '{\"references\":[{\"title\":\"42\",\"part\":\"412\"}]}'::jsonb\n",
        "ORDER BY posted_date DESC NULLS LAST\n",
        "LIMIT 25;\n",
        "\"\"\"\n",
        "\n",
        "print(\"Status query:\\n\", status_query)\n",
        "print(\"Triage query:\\n\", triage_query)\n",
        "print(\"42 CFR Part 412 query:\\n\", part_412_query)\n",
        "\n",
        "# Optional execution:\n",
        "# import psycopg\n",
        "# with psycopg.connect(DATABASE_URL) as conn:\n",
        "#     with conn.cursor() as cur:\n",
        "#         cur.execute(status_query)\n",
        "#         print(cur.fetchall())"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "0c77b5c8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Operational Checklist\n",
        "\n",
        "- [ ] Confirm `DATABASE_URL` and `API_KEY`\n",
        "- [ ] Run dry-run on a representative docket\n",
        "- [ ] Ingest one or more dockets into Postgres\n",
        "- [ ] Review parse status counts\n",
        "- [ ] Export examples of `unparsed` and `missing_title`\n",
        "- [ ] Improve parser rules if needed (`cfr_part_normalization.py`)\n",
        "- [ ] Re-ingest targeted dockets and compare quality metrics"
      ],
      "id": "15340273"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}